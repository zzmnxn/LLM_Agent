"""
- tools.py should export:
  * get_tools() -> List[BaseTool] OR
  * tools: List[BaseTool]
  
- prompts.py should export:
  * get_prompt() -> ChatPromptTemplate OR
  * prompt: ChatPromptTemplate
  
- agent_builder.py should export (optional):
  * build_agent_executor(tools, prompt, llm) -> AgentExecutor OR
  * get_agent_executor(tools, prompt, llm) -> AgentExecutor
  
If these are not available, the app will use mock implementations.
"""

import streamlit as st
import os
from typing import List, Dict, Any, Optional
from datetime import datetime

# LangChain imports
try:
    from langchain_core.callbacks import BaseCallbackHandler
except ImportError:
    from langchain.callbacks.base import BaseCallbackHandler
from langchain_openai import ChatOpenAI
from langchain_classic.agents import AgentExecutor, create_openai_tools_agent
from langchain_classic import hub
from langchain_core.tools import BaseTool
from langchain_core.prompts import ChatPromptTemplate

# Set page config
st.set_page_config(
    page_title="âœˆï¸ ì—¬í–‰ ê³„íš Agent",
    page_icon="âœˆï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Tool emoji mapping for visual appeal
TOOL_EMOJIS = {
    "ë‚ ì”¨": "ğŸŒ¤ï¸",
    "weather": "ğŸŒ¤ï¸",
    "ë§›ì§‘": "ğŸ½ï¸",
    "restaurant": "ğŸ½ï¸",
    "ê´€ê´‘": "ğŸ›ï¸",
    "attraction": "ğŸ›ï¸",
    "êµí†µ": "ğŸšŒ",
    "transport": "ğŸšŒ",
    "ìœ„í—˜": "âš ï¸",
    "risk": "âš ï¸",
    "í™˜ìœ¨": "ğŸ’±",
    "exchange": "ğŸ’±",
    "ì˜ˆì‚°": "ğŸ’°",
    "budget": "ğŸ’°",
    "ì¼ì •": "ğŸ“…",
    "schedule": "ğŸ“…",
    "d-day": "ğŸ“†",
    "ê²€ìƒ‰": "ğŸ”",
    "search": "ğŸ”",
    "tavily": "ğŸ”",
}


class StreamlitAgentCallbackHandler(BaseCallbackHandler):
    """Custom callback handler to visualize agent thinking process in Streamlit"""
    
    def __init__(self):
        self.tool_executions = []
        self.current_tool = None
        
    def on_tool_start(self, serialized: Dict[str, Any], input_str: str, **kwargs) -> None:
        """Called when a tool starts executing"""
        tool_name = serialized.get("name", "unknown_tool")
        self.current_tool = {
            "name": tool_name,
            "input": input_str,
            "status": "running",
            "start_time": datetime.now(),
            "output": None
        }
        self.tool_executions.append(self.current_tool)
        
        # Update session state
        if "tool_executions" not in st.session_state:
            st.session_state.tool_executions = []
        st.session_state.tool_executions.append(self.current_tool)
        
    def on_tool_end(self, output: str, **kwargs) -> None:
        """Called when a tool finishes executing"""
        if self.current_tool:
            self.current_tool["status"] = "completed"
            self.current_tool["output"] = str(output)
            self.current_tool["end_time"] = datetime.now()
            self.current_tool = None
    
    def on_tool_error(self, error: Exception, **kwargs) -> None:
        """Called when a tool encounters an error"""
        if self.current_tool:
            self.current_tool["status"] = "error"
            self.current_tool["error"] = str(error)
            self.current_tool = None
    
    def get_tool_emoji(self, tool_name: str) -> str:
        """Get emoji for tool based on name"""
        tool_lower = tool_name.lower()
        for key, emoji in TOOL_EMOJIS.items():
            if key in tool_lower:
                return emoji
        return "ğŸ”§"


def get_tool_emoji(tool_name: str) -> str:
    """Helper function to get emoji for tool"""
    tool_lower = tool_name.lower()
    for key, emoji in TOOL_EMOJIS.items():
        if key in tool_lower:
            return emoji
    return "ğŸ”§"


def initialize_agent(use_mock: bool = False):
    """
    Initialize agent with graceful fallback to mock implementation
    
    Expected interface:
    - tools.py should export: get_tools() -> List[BaseTool] or tools: List[BaseTool]
    - prompts.py should export: get_prompt() -> ChatPromptTemplate or prompt: ChatPromptTemplate
    - agent_builder.py should export: build_agent_executor(tools, prompt, llm) -> AgentExecutor
    """
    # Import build_agent_executor from agent_builder (ìš°ì„ ì ìœ¼ë¡œ ì‚¬ìš©)
    try:
        from agent_builder import build_agent_executor
    except ImportError:
        build_agent_executor = None
    
    try:
        # Try to import from Team Member A's files
        # Try different import patterns for tools
        try:
            from tools import get_tools
            tools = get_tools()
        except (ImportError, AttributeError):
            try:
                from tools import tools as tools_list
                tools = tools_list
            except (ImportError, AttributeError):
                raise ImportError("tools.pyì—ì„œ toolsë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # Try different import patterns for prompts
        try:
            from prompts import get_prompt
            prompt = get_prompt()
        except (ImportError, AttributeError):
            try:
                from prompts import prompt as prompt_template
                prompt = prompt_template
            except (ImportError, AttributeError):
                # Fallback to default prompt from hub
                prompt = hub.pull("hwchase17/openai-functions-agent")
        
        # Initialize LLM
        llm = ChatOpenAI(
            model=st.session_state.get("model", "gpt-4o-mini"),
            temperature=st.session_state.get("temperature", 0),
            api_key=st.session_state.get("OPENAI_API_KEY")
        )
        
        # Use build_agent_executor from agent_builder if available
        if build_agent_executor:
            agent_executor = build_agent_executor(tools, prompt, llm)
        else:
            # Fallback: build agent executor directly
            agent = create_openai_tools_agent(llm, tools, prompt)
            agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)
        
        return agent_executor, False  # False means not using mock
        
    except (ImportError, AttributeError, TypeError) as e:
        # Fallback to mock implementation
        if use_mock:
            return create_mock_agent(), True  # True means using mock
        else:
            # Try one more time with alternative patterns
            try:
                from tools import tools as tools_list
                from prompts import prompt as prompt_template
                
                llm = ChatOpenAI(
                    model=st.session_state.get("model", "gpt-4o-mini"),
                    temperature=st.session_state.get("temperature", 0),
                    api_key=st.session_state.get("OPENAI_API_KEY")
                )
                
                if build_agent_executor:
                    agent_executor = build_agent_executor(tools_list, prompt_template, llm)
                else:
                    agent = create_openai_tools_agent(llm, tools_list, prompt_template)
                    agent_executor = AgentExecutor(agent=agent, tools=tools_list, verbose=True)
                
                return agent_executor, False
            except:
                return create_mock_agent(), True


def create_mock_agent():
    """Create a mock agent for development when Team Member A's code is not ready"""
    from langchain_core.tools import tool
    from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
    
    @tool
    def mock_weather_search(query: str) -> str:
        """ë‚ ì”¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤. ì‚¬ìš©ìê°€ ì œê³µí•œ ëª©ì ì§€ì™€ ë‚ ì§œì— ëŒ€í•œ ë‚ ì”¨ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        return f"ì œì£¼ë„ ë‚ ì”¨: ë§‘ìŒ, 15Â°C, ê°•í’ ì£¼ì˜ (1ì›” ê¸°ì¤€)"
    
    @tool
    def mock_restaurant_search(query: str) -> str:
        """ë§›ì§‘ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì„ í˜¸ì‚¬í•­(í•´ì‚°ë¬¼ ë“±)ì„ ê³ ë ¤í•˜ì—¬ ì¶”ì²œí•©ë‹ˆë‹¤."""
        return f"í•´ì‚°ë¬¼ ë§›ì§‘ ì¶”ì²œ: í•´ë…€ì˜ ì§‘, ë°”ë‹¤í–¥, í•´ë¬¼íƒ• ì „ë¬¸ì , ê°ˆì¹˜ì¡°ë¦¼ ì „ë¬¸ì "
    
    @tool
    def mock_attraction_search(query: str) -> str:
        """ê´€ê´‘ ëª…ì†Œ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤. ëª©ì ì§€ì˜ ì¸ê¸° ê´€ê´‘ì§€ì™€ ëŒ€ì¤‘êµí†µ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤."""
        return f"ê´€ê´‘ ëª…ì†Œ: í•œë¼ì‚°, ì„±ì‚°ì¼ì¶œë´‰, ìš°ë„, ì„­ì§€ì½”ì§€, ì¹´ë©œë¦¬ì•„í, ì•„ì¿ ì•„í”Œë¼ë„·"
    
    mock_tools = [mock_weather_search, mock_restaurant_search, mock_attraction_search]
    
    llm = ChatOpenAI(
        model=st.session_state.get("model", "gpt-4o-mini"),
        temperature=st.session_state.get("temperature", 0),
        api_key=st.session_state.get("OPENAI_API_KEY")
    )
    
    # ì—¬í–‰ ê³„íš ì „ë¬¸ prompt
    prompt = ChatPromptTemplate.from_messages([
        ("system", """ë‹¹ì‹ ì€ ì „ë¬¸ ì—¬í–‰ ê³„íš Agentì…ë‹ˆë‹¤. ì‚¬ìš©ìê°€ ì œê³µí•œ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¦‰ì‹œ ì—¬í–‰ ê³„íšì„ ì„¸ì›Œì£¼ì„¸ìš”.

ì‚¬ìš©ìê°€ ì´ë¯¸ ì œê³µí•œ ì •ë³´:
- ëª©ì ì§€, ê¸°ê°„, ì˜ˆì‚°, ì„ í˜¸ì‚¬í•­ ë“±ì´ ì‚¬ìš©ì ì…ë ¥ì— í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
- ì¶”ê°€ ì§ˆë¬¸ì„ í•˜ì§€ ë§ê³ , ì œê³µëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë°”ë¡œ ì—¬í–‰ ê³„íšì„ ì„¸ì›Œì£¼ì„¸ìš”.

ì—¬í–‰ ê³„íšì—ëŠ” ë‹¤ìŒì´ í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤:
1. ì¼ì •ë³„ ìƒì„¸ ê³„íš (ë‚ ì§œë³„ë¡œ)
2. ì¶”ì²œ ê´€ê´‘ì§€ ë° í™œë™
3. ë§›ì§‘ ì¶”ì²œ (ì„ í˜¸ì‚¬í•­ ë°˜ì˜)
4. ì˜ˆì‚° ë°°ë¶„
5. ë‚ ì”¨ ì •ë³´ ë° ì¤€ë¹„ë¬¼
6. êµí†µ ì •ë³´

ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ë¥¼ í™œìš©í•˜ì—¬ ì‹¤ì œ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³ , êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì—¬í–‰ ê³„íšì„ ì œê³µí•˜ì„¸ìš”."""),
        ("user", "{input}"),
        MessagesPlaceholder("agent_scratchpad")
    ])
    
    agent = create_openai_tools_agent(llm, mock_tools, prompt)
    agent_executor = AgentExecutor(agent=agent, tools=mock_tools, verbose=True)
    
    return agent_executor


def display_thinking_process():
    """Display the agent's thinking process with tool executions"""
    if "tool_executions" not in st.session_state or not st.session_state.tool_executions:
        return
    
    st.markdown("### ğŸ¤” Agentê°€ ì‘ì—… ì¤‘ì…ë‹ˆë‹¤...")
    
    # Group tools by status
    running_tools = [t for t in st.session_state.tool_executions if t.get("status") == "running"]
    completed_tools = [t for t in st.session_state.tool_executions if t.get("status") == "completed"]
    error_tools = [t for t in st.session_state.tool_executions if t.get("status") == "error"]
    
    # Show running tools first
    if running_tools:
        st.markdown("#### ğŸ”„ ì‹¤í–‰ ì¤‘ì¸ ë„êµ¬")
        for tool_exec in running_tools[-3:]:  # Show last 3 running
            tool_name = tool_exec.get("name", "unknown")
            emoji = get_tool_emoji(tool_name)
            st.info(f"{emoji} **{tool_name}** ì‹¤í–‰ ì¤‘... | ì…ë ¥: {tool_exec.get('input', 'N/A')[:100]}")
    
    # Show completed tools
    if completed_tools:
        st.markdown("#### âœ… ì™„ë£Œëœ ë„êµ¬")
    for tool_exec in completed_tools[-5:]:  # Show last 5 completed
        tool_name = tool_exec.get("name", "unknown")
        emoji = get_tool_emoji(tool_name)
        
        with st.expander(f"{emoji} âœ… {tool_name} - ì™„ë£Œ", expanded=False):
            st.info(f"**ì…ë ¥:** {tool_exec.get('input', 'N/A')}")
            output = tool_exec.get('output', 'N/A')
            if len(str(output)) > 500:
                st.text_area("**ì¶œë ¥:**", value=str(output)[:500] + "...", height=100, disabled=True, key=f"output_{tool_name}_{id(tool_exec)}")
            else:
                st.text_area("**ì¶œë ¥:**", value=str(output), height=100, disabled=True, key=f"output_{tool_name}_{id(tool_exec)}")
    
    # Show error tools
    if error_tools:
        st.markdown("#### âŒ ì˜¤ë¥˜ê°€ ë°œìƒí•œ ë„êµ¬")
    for tool_exec in error_tools:
        tool_name = tool_exec.get("name", "unknown")
        emoji = get_tool_emoji(tool_name)
        with st.expander(f"{emoji} âŒ {tool_name} - ì˜¤ë¥˜", expanded=True):
            st.error(f"**ì—ëŸ¬:** {tool_exec.get('error', 'Unknown error')}")
            st.info(f"**ì…ë ¥:** {tool_exec.get('input', 'N/A')}")


def initialize_session_state():
    """Initialize Streamlit session state variables"""
    if "messages" not in st.session_state:
        st.session_state.messages = []
    
    if "tool_executions" not in st.session_state:
        st.session_state.tool_executions = []
    
    if "OPENAI_API_KEY" not in st.session_state:
        st.session_state.OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
    
    if "TAVILY_API_KEY" not in st.session_state:
        st.session_state.TAVILY_API_KEY = os.getenv("TAVILY_API_KEY", "")
    
    if "model" not in st.session_state:
        st.session_state.model = "gpt-4o-mini"
    
    if "temperature" not in st.session_state:
        st.session_state.temperature = 0.0
    
    if "use_mock" not in st.session_state:
        st.session_state.use_mock = False
    
    if "pending_query" not in st.session_state:
        st.session_state.pending_query = None


def execute_agent_query(user_query: str):
    """Execute agent with user query and display results"""
    # Display user message
    with st.chat_message("user"):
        st.markdown(user_query)
    
    # Clear previous tool executions
    st.session_state.tool_executions = []
    
    # Initialize callback handler
    callback_handler = StreamlitAgentCallbackHandler()
    
    # Initialize agent
    try:
        agent_executor, is_mock = initialize_agent(use_mock=st.session_state.use_mock)
        
        if is_mock:
            st.info("âš ï¸ ê°œë°œ ëª¨ë“œ: Mock Agentë¥¼ ì‚¬ìš© ì¤‘ì…ë‹ˆë‹¤")
        
        # Display thinking process area
        with st.chat_message("assistant"):
            thinking_placeholder = st.empty()
            
            # Show thinking process
            with thinking_placeholder.container():
                display_thinking_process()
            
            # Execute agent
            with st.spinner("ğŸ¤” ì—¬í–‰ ê³„íš ìƒì„± ì¤‘..."):
                try:
                    result = agent_executor.invoke(
                        {"input": user_query},
                        {"callbacks": [callback_handler]}
                    )
                    
                    # Update thinking process display
                    thinking_placeholder.empty()
                    with thinking_placeholder.container():
                        display_thinking_process()
                    
                    # Display response
                    response = result.get("output", "ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    st.markdown(response)
                    
                    # Save to chat history
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": response,
                        "tool_executions": st.session_state.tool_executions.copy()
                    })
                    
                except Exception as e:
                    error_msg = str(e)
                    
                    # Check for specific error types
                    if "api" in error_msg.lower() or "key" in error_msg.lower():
                        st.error("âŒ API í‚¤ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
                    elif "rate limit" in error_msg.lower():
                        st.error("â±ï¸ API í˜¸ì¶œ í•œë„ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
                    else:
                        st.error("ğŸ˜” ì ì‹œ ë¬¸ì œê°€ ìƒê²¼ì–´ìš”. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
                    
                    # Show error details in expander for debugging
                    with st.expander("ğŸ” ì˜¤ë¥˜ ìƒì„¸ ì •ë³´ (ê°œë°œìš©)"):
                        st.exception(e)
                    
                    # Save error message to chat
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": "ì£„ì†¡í•©ë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
                        "error": error_msg
                    })
    
    except Exception as e:
        st.error("ğŸ˜” Agent ì´ˆê¸°í™” ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        with st.expander("ğŸ” ì˜¤ë¥˜ ìƒì„¸ ì •ë³´ (ê°œë°œìš©)"):
            st.exception(e)


def main():
    """Main Streamlit application"""
    initialize_session_state()
    
    # Title
    st.title("âœˆï¸ ì—¬í–‰ ê³„íš Agent")
    st.markdown("---")
    
    # Sidebar
    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì •")
        
        # API Keys
        st.subheader("ğŸ”‘ API í‚¤")
        openai_key = st.text_input(
            "OpenAI API Key",
            value=st.session_state.OPENAI_API_KEY,
            type="password",
            help="OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”"
        )
        if openai_key:
            st.session_state.OPENAI_API_KEY = openai_key
            os.environ["OPENAI_API_KEY"] = openai_key
        
        tavily_key = st.text_input(
            "Tavily API Key",
            value=st.session_state.TAVILY_API_KEY,
            type="password",
            help="Tavily API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì„ íƒì‚¬í•­)"
        )
        if tavily_key:
            st.session_state.TAVILY_API_KEY = tavily_key
            os.environ["TAVILY_API_KEY"] = tavily_key
        
        st.markdown("---")
        
        # Model Settings
        st.subheader("ğŸ¤– ëª¨ë¸ ì„¤ì •")
        model = st.selectbox(
            "ëª¨ë¸ ì„ íƒ",
            ["gpt-4o-mini", "gpt-4o", "gpt-4-turbo"],
            index=0 if st.session_state.model == "gpt-4o-mini" else 1
        )
        st.session_state.model = model
        
        temperature = st.slider("Temperature", 0.0, 1.0, float(st.session_state.temperature), 0.1)
        st.session_state.temperature = temperature
        
        st.markdown("---")
        
        # Development Mode
        st.subheader("ğŸ› ï¸ ê°œë°œ ëª¨ë“œ")
        use_mock = st.checkbox("Mock Agent ì‚¬ìš© (ê°œë°œìš©)", value=st.session_state.use_mock)
        st.session_state.use_mock = use_mock
        
        if use_mock:
            st.warning("âš ï¸ Mock Agent ëª¨ë“œ í™œì„±í™”")
        
        st.markdown("---")
        
        # Clear Chat
        if st.button("ğŸ—‘ï¸ ì±„íŒ… ê¸°ë¡ ì§€ìš°ê¸°"):
            st.session_state.messages = []
            st.session_state.tool_executions = []
            st.rerun()
    
    # Main area
    # Input form for quick start
    with st.expander("ğŸ“ ë¹ ë¥¸ ì‹œì‘ (ì—¬í–‰ ì •ë³´ ì…ë ¥)", expanded=False):
        col1, col2 = st.columns(2)
        with col1:
            destination = st.text_input("ëª©ì ì§€", placeholder="ì˜ˆ: ì œì£¼ë„")
            duration = st.text_input("ê¸°ê°„", placeholder="ì˜ˆ: 3ë°• 4ì¼")
        with col2:
            budget = st.text_input("ì˜ˆì‚°", placeholder="ì˜ˆ: 50ë§Œì›")
            preferences = st.text_input("ì„ í˜¸ì‚¬í•­", placeholder="ì˜ˆ: í•´ì‚°ë¬¼ ì¢‹ì•„í•´")
        
        example_query = st.button("ğŸ“‹ ì˜ˆì œ ì¿¼ë¦¬ ì‚¬ìš©", help="3ë°• 4ì¼ ì œì£¼ë„ ì—¬í–‰ ê³„íš ì§œì¤˜, ì˜ˆì‚° 50ë§Œì›, í•´ì‚°ë¬¼ ì¢‹ì•„í•´")
        
        if st.button("ğŸš€ ì—¬í–‰ ê³„íš ìš”ì²­") or example_query:
            query_parts = []
            if destination or example_query:
                if example_query:
                    user_input = "3ë°• 4ì¼ ì œì£¼ë„ ì—¬í–‰ ê³„íš ì§œì¤˜, ì˜ˆì‚° 50ë§Œì›, í•´ì‚°ë¬¼ ì¢‹ì•„í•´"
                else:
                    query_parts = []
                    if destination:
                        query_parts.append(f"ëª©ì ì§€: {destination}")
                    if duration:
                        query_parts.append(f"ê¸°ê°„: {duration}")
                    if budget:
                        query_parts.append(f"ì˜ˆì‚°: {budget}")
                    if preferences:
                        query_parts.append(f"ì„ í˜¸ì‚¬í•­: {preferences}")
                    user_input = ", ".join(query_parts) if query_parts else destination
                
                # Add to chat
                st.session_state.messages.append({"role": "user", "content": user_input})
                # Store the query to process it after rerun
                st.session_state.pending_query = user_input
                st.rerun()
    
    # Process pending query from button click
    if st.session_state.pending_query:
        pending = st.session_state.pending_query
        st.session_state.pending_query = None  # Clear pending query
        execute_agent_query(pending)
    
    # Display chat history
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
            
            # Show tool executions if this is an assistant message
            if message["role"] == "assistant" and "tool_executions" in message:
                display_thinking_process()
    
    # Chat input
    if prompt := st.chat_input("ì—¬í–‰ ê³„íšì„ ìš”ì²­í•˜ì„¸ìš”..."):
        # Add user message
        st.session_state.messages.append({"role": "user", "content": prompt})
        execute_agent_query(prompt)


if __name__ == "__main__":
    main()

ì—¬í–‰ ê³„íš AI ë¹„ì„œ - Main Application
"""

import os
from dotenv import load_dotenv
from agent_builder import build_travel_agent

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (.env íŒŒì¼)
load_dotenv()

def main():
    # API í‚¤ í™•ì¸
    if not os.environ.get("OPENAI_API_KEY"):
        print("âŒ ì˜¤ë¥˜: OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
        return
    if not os.environ.get("TAVILY_API_KEY"):
        print("âŒ ì˜¤ë¥˜: TAVILY_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
        return

    print("=" * 60)
    print("âœˆï¸  ì—¬í–‰ ê³„íš AI ë¹„ì„œ v2.0 ì‹œì‘")
    print("=" * 60)

    # ì—ì´ì „íŠ¸ ë¹Œë“œ
    try:
        agent = build_travel_agent()
    except Exception as e:
        print(f"âŒ ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return

    # ì‚¬ìš©ì ì…ë ¥ (MD íŒŒì¼ì˜ ì˜ˆì‹œ ì‚¬ìš©)
    default_input = "3ë°• 4ì¼ ì œì£¼ë„ ì—¬í–‰ ê³„íš ì§œì¤˜, ì˜ˆì‚° 50ë§Œì›, í•´ì‚°ë¬¼ ì¢‹ì•„í•´, 1ì›” 15ì¼ ì¶œë°œ"
    
    print("\nğŸ’¡ ì˜ˆì‹œ ì…ë ¥:")
    print(f'"{default_input}"')
    
    user_input = input("\nì—¬í–‰ ìš”ì²­ì‚¬í•­ì„ ì…ë ¥í•˜ì„¸ìš” (ì—”í„° ì‹œ ì˜ˆì‹œ ì‹¤í–‰): ").strip()
    
    if not user_input:
        user_input = default_input

    print(f"\nğŸ”„ [ì§„í–‰ ì¤‘] '{user_input}'ì— ëŒ€í•œ ì—¬í–‰ ê³„íšì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...\n")
    print("-" * 60)

    # ì—ì´ì „íŠ¸ ì‹¤í–‰
    try:
        result = agent.invoke({"input": user_input})
        
        print("\n" + "=" * 60)
        print("âœ… [ì™„ë£Œ] ì—¬í–‰ ê³„íš ìƒì„± ê²°ê³¼")
        print("=" * 60 + "\n")
        print(result["output"])
        
        # ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥
        with open("result_plan.md", "w", encoding="utf-8") as f:
            f.write(result["output"])
        print("\nğŸ“„ ê²°ê³¼ê°€ 'result_plan.md' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    except Exception as e:
        print(f"\nâŒ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

if __name__ == "__main__":
    main()
