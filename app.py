"""
- tools.py should export:
  * get_tools() -> List[BaseTool] OR
  * tools: List[BaseTool]
  
- prompts.py should export:
  * get_prompt() -> ChatPromptTemplate OR
  * prompt: ChatPromptTemplate
  
- agent_builder.py should export (optional):
  * build_agent_executor(tools, prompt, llm) -> AgentExecutor OR
  * get_agent_executor(tools, prompt, llm) -> AgentExecutor
  
If these are not available, the app will use mock implementations.
"""

import streamlit as st
import os
from typing import List, Dict, Any, Optional
from datetime import datetime

# LangChain imports
try:
    from langchain_core.callbacks import BaseCallbackHandler
except ImportError:
    from langchain.callbacks.base import BaseCallbackHandler
from langchain_openai import ChatOpenAI
from langchain_classic.agents import AgentExecutor, create_openai_tools_agent
from langchain_classic import hub
from langchain_core.tools import BaseTool
from langchain_core.prompts import ChatPromptTemplate

# Set page config
st.set_page_config(
    page_title="âœˆï¸ ì—¬í–‰ ê³„íš Agent",
    page_icon="âœˆï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Tool emoji mapping for visual appeal
TOOL_EMOJIS = {
    "ë‚ ì”¨": "ğŸŒ¤ï¸",
    "weather": "ğŸŒ¤ï¸",
    "search_weather": "ğŸŒ¤ï¸",
    "ë§›ì§‘": "ğŸ½ï¸",
    "restaurant": "ğŸ½ï¸",
    "ê´€ê´‘": "ğŸ›ï¸",
    "attraction": "ğŸ›ï¸",
    "êµí†µ": "ğŸšŒ",
    "transport": "ğŸšŒ",
    "ìœ„í—˜": "âš ï¸",
    "risk": "âš ï¸",
    "í™˜ìœ¨": "ğŸ’±",
    "exchange": "ğŸ’±",
    "ì˜ˆì‚°": "ğŸ’°",
    "budget": "ğŸ’°",
    "ì¼ì •": "ğŸ“…",
    "schedule": "ğŸ“…",
    "d-day": "ğŸ“†",
    "ê²€ìƒ‰": "ğŸ”",
    "search": "ğŸ”",
    "tavily": "ğŸ”",
}


class StreamlitAgentCallbackHandler(BaseCallbackHandler):
    """Custom callback handler to visualize agent thinking process in Streamlit"""
    
    def __init__(self, result_container=None):
        self.tool_executions = []
        self.current_tool = None
        self.result_container = result_container  # ì‹¤ì‹œê°„ ê²°ê³¼ í‘œì‹œìš© ì»¨í…Œì´ë„ˆ
        
    def on_tool_start(self, serialized: Dict[str, Any], input_str: str, **kwargs) -> None:
        """Called when a tool starts executing"""
        tool_name = serialized.get("name", "unknown_tool")
        self.current_tool = {
            "name": tool_name,
            "input": input_str,
            "status": "running",
            "start_time": datetime.now(),
            "output": None
        }
        self.tool_executions.append(self.current_tool)
        
        # Update session state
        if "tool_executions" not in st.session_state:
            st.session_state.tool_executions = []
        st.session_state.tool_executions.append(self.current_tool)
        
        # ì‹¤ì‹œê°„ìœ¼ë¡œ ì‹¤í–‰ ì¤‘ì¸ tool í‘œì‹œ
        if self.result_container:
            with self.result_container:
                emoji = get_tool_emoji(tool_name)
                st.info(f"{emoji} **{tool_name}** ì‹¤í–‰ ì¤‘... | ì…ë ¥: {str(input_str)[:100]}")
        
    def on_tool_end(self, output, **kwargs) -> None:
        """Called when a tool finishes executing"""
        if self.current_tool:
            self.current_tool["status"] = "completed"
            # outputì„ ì›ë³¸ í˜•íƒœë¡œ ì €ì¥ (dictì¼ ìˆ˜ ìˆìŒ)
            self.current_tool["output"] = output
            self.current_tool["end_time"] = datetime.now()
            
            # ì‹¤ì‹œê°„ìœ¼ë¡œ ì™„ë£Œëœ tool ê²°ê³¼ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ í‘œì‹œ
            if self.result_container:
                with self.result_container:
                    tool_name = self.current_tool["name"]
                    emoji = get_tool_emoji(tool_name)
                    
                    # JSON í˜•ì‹ìœ¼ë¡œ ê²°ê³¼ í‘œì‹œ
                    try:
                        import json
                        # outputì´ dictë‚˜ listì¸ ê²½ìš° ì§ì ‘ st.json() ì‚¬ìš©
                        if isinstance(output, (dict, list)):
                            with st.expander(f"{emoji} âœ… {tool_name} - ì™„ë£Œ", expanded=True):
                                st.json(output)
                        else:
                            # ë¬¸ìì—´ì¸ ê²½ìš° JSON íŒŒì‹± ì‹œë„
                            try:
                                parsed = json.loads(str(output))
                                with st.expander(f"{emoji} âœ… {tool_name} - ì™„ë£Œ", expanded=True):
                                    st.json(parsed)
                            except:
                                # JSONì´ ì•„ë‹Œ ê²½ìš° ì¼ë°˜ í…ìŠ¤íŠ¸ë¡œ í‘œì‹œ
                                with st.expander(f"{emoji} âœ… {tool_name} - ì™„ë£Œ", expanded=True):
                                    st.text_area("**ì¶œë ¥:**", value=str(output), height=200, disabled=True)
                    except Exception as e:
                        # ì˜ˆì™¸ ë°œìƒ ì‹œ ì¼ë°˜ í…ìŠ¤íŠ¸ë¡œ í‘œì‹œ
                        with st.expander(f"{emoji} âœ… {tool_name} - ì™„ë£Œ", expanded=True):
                            st.text_area("**ì¶œë ¥:**", value=str(output), height=200, disabled=True)
            
            self.current_tool = None
    
    def on_tool_error(self, error: Exception, **kwargs) -> None:
        """Called when a tool encounters an error"""
        if self.current_tool:
            self.current_tool["status"] = "error"
            self.current_tool["error"] = str(error)
            self.current_tool = None
    
    def get_tool_emoji(self, tool_name: str) -> str:
        """Get emoji for tool based on name"""
        tool_lower = tool_name.lower()
        for key, emoji in TOOL_EMOJIS.items():
            if key in tool_lower:
                return emoji
        return "ğŸ”§"


def get_tool_emoji(tool_name: str) -> str:
    """Helper function to get emoji for tool"""
    tool_lower = tool_name.lower()
    for key, emoji in TOOL_EMOJIS.items():
        if key in tool_lower:
            return emoji
    return "ğŸ”§"


def initialize_agent(use_mock: bool = False):
    """
    Initialize agent with graceful fallback to mock implementation
    
    Expected interface:
    - tools.py should export: get_tools() -> List[BaseTool] or tools: List[BaseTool]
    - prompts.py should export: get_prompt() -> ChatPromptTemplate or prompt: ChatPromptTemplate
    - agent_builder.py should export: build_agent_executor(tools, prompt, llm) -> AgentExecutor
    """
    # Import build_agent_executor from agent_builder (ìš°ì„ ì ìœ¼ë¡œ ì‚¬ìš©)
    try:
        from agent_builder import build_agent_executor
    except ImportError:
        build_agent_executor = None
    
    try:
        # Try to import from Team Member A's files
        # Import tools - tools.py exports ALL_TOOLS
        try:
            from tools import ALL_TOOLS
            tools = ALL_TOOLS
        except (ImportError, AttributeError):
            # Fallback: try get_tools() function
            try:
                from tools import get_tools
                tools = get_tools()
            except (ImportError, AttributeError):
                # Fallback: try tools variable
                try:
                    from tools import tools as tools_list
                    tools = tools_list
                except (ImportError, AttributeError):
                    raise ImportError("tools.pyì—ì„œ toolsë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # Import prompts - prompts.py exports get_agent_prompt()
        try:
            from prompts import get_agent_prompt
            prompt = get_agent_prompt()
        except (ImportError, AttributeError):
            # Fallback: try get_prompt() function
            try:
                from prompts import get_prompt
                prompt = get_prompt()
            except (ImportError, AttributeError):
                # Fallback: try prompt variable
                try:
                    from prompts import prompt as prompt_template
                    prompt = prompt_template
                except (ImportError, AttributeError):
                    # Fallback to default prompt from hub
                    prompt = hub.pull("hwchase17/openai-functions-agent")
        
        # Initialize LLM
        llm = ChatOpenAI(
            model=st.session_state.get("model", "gpt-4o-mini"),
            temperature=st.session_state.get("temperature", 0),
            api_key=st.session_state.get("OPENAI_API_KEY")
        )
        
        # Use build_agent_executor from agent_builder if available
        if build_agent_executor:
            agent_executor = build_agent_executor(tools, prompt, llm)
        else:
            # Fallback: build agent executor directly
            agent = create_openai_tools_agent(llm, tools, prompt)
            agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)
        
        return agent_executor, False  # False means not using mock
        
    except (ImportError, AttributeError, TypeError) as e:
        # Fallback to mock implementation
        if use_mock:
            return create_mock_agent(), True  # True means using mock
        else:
            # Try one more time with alternative patterns
            try:
                # Try ALL_TOOLS
                try:
                    from tools import ALL_TOOLS
                    tools_list = ALL_TOOLS
                except (ImportError, AttributeError):
                    from tools import tools as tools_list
                
                # Try get_agent_prompt
                try:
                    from prompts import get_agent_prompt
                    prompt_template = get_agent_prompt()
                except (ImportError, AttributeError):
                    try:
                        from prompts import get_prompt
                        prompt_template = get_prompt()
                    except (ImportError, AttributeError):
                        from prompts import prompt as prompt_template
                
                llm = ChatOpenAI(
                    model=st.session_state.get("model", "gpt-4o-mini"),
                    temperature=st.session_state.get("temperature", 0),
                    api_key=st.session_state.get("OPENAI_API_KEY")
                )
                
                if build_agent_executor:
                    agent_executor = build_agent_executor(tools_list, prompt_template, llm)
                else:
                    agent = create_openai_tools_agent(llm, tools_list, prompt_template)
                    agent_executor = AgentExecutor(agent=agent, tools=tools_list, verbose=True)
                
                return agent_executor, False
            except:
                return create_mock_agent(), True


def create_mock_agent():
    """Create a mock agent for development when Team Member A's code is not ready"""
    from langchain_core.tools import tool
    from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
    
    @tool
    def mock_weather_search(query: str) -> str:
        """ë‚ ì”¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤. ì‚¬ìš©ìê°€ ì œê³µí•œ ëª©ì ì§€ì™€ ë‚ ì§œì— ëŒ€í•œ ë‚ ì”¨ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        return f"ì œì£¼ë„ ë‚ ì”¨: ë§‘ìŒ, 15Â°C, ê°•í’ ì£¼ì˜ (1ì›” ê¸°ì¤€)"
    
    @tool
    def mock_restaurant_search(query: str) -> str:
        """ë§›ì§‘ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì„ í˜¸ì‚¬í•­(í•´ì‚°ë¬¼ ë“±)ì„ ê³ ë ¤í•˜ì—¬ ì¶”ì²œí•©ë‹ˆë‹¤."""
        return f"í•´ì‚°ë¬¼ ë§›ì§‘ ì¶”ì²œ: í•´ë…€ì˜ ì§‘, ë°”ë‹¤í–¥, í•´ë¬¼íƒ• ì „ë¬¸ì , ê°ˆì¹˜ì¡°ë¦¼ ì „ë¬¸ì "
    
    @tool
    def mock_attraction_search(query: str) -> str:
        """ê´€ê´‘ ëª…ì†Œ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤. ëª©ì ì§€ì˜ ì¸ê¸° ê´€ê´‘ì§€ì™€ ëŒ€ì¤‘êµí†µ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤."""
        return f"ê´€ê´‘ ëª…ì†Œ: í•œë¼ì‚°, ì„±ì‚°ì¼ì¶œë´‰, ìš°ë„, ì„­ì§€ì½”ì§€, ì¹´ë©œë¦¬ì•„í, ì•„ì¿ ì•„í”Œë¼ë„·"
    
    mock_tools = [mock_weather_search, mock_restaurant_search, mock_attraction_search]
    
    llm = ChatOpenAI(
        model=st.session_state.get("model", "gpt-4o-mini"),
        temperature=st.session_state.get("temperature", 0),
        api_key=st.session_state.get("OPENAI_API_KEY")
    )
    
    # ì—¬í–‰ ê³„íš ì „ë¬¸ prompt
    prompt = ChatPromptTemplate.from_messages([
        ("system", """ë‹¹ì‹ ì€ ì „ë¬¸ ì—¬í–‰ ê³„íš Agentì…ë‹ˆë‹¤. ì‚¬ìš©ìê°€ ì œê³µí•œ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¦‰ì‹œ ì—¬í–‰ ê³„íšì„ ì„¸ì›Œì£¼ì„¸ìš”.

ì‚¬ìš©ìê°€ ì´ë¯¸ ì œê³µí•œ ì •ë³´:
- ëª©ì ì§€, ê¸°ê°„, ì˜ˆì‚°, ì„ í˜¸ì‚¬í•­ ë“±ì´ ì‚¬ìš©ì ì…ë ¥ì— í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
- ì¶”ê°€ ì§ˆë¬¸ì„ í•˜ì§€ ë§ê³ , ì œê³µëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë°”ë¡œ ì—¬í–‰ ê³„íšì„ ì„¸ì›Œì£¼ì„¸ìš”.

ì—¬í–‰ ê³„íšì—ëŠ” ë‹¤ìŒì´ í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤:
1. ì¼ì •ë³„ ìƒì„¸ ê³„íš (ë‚ ì§œë³„ë¡œ)
2. ì¶”ì²œ ê´€ê´‘ì§€ ë° í™œë™
3. ë§›ì§‘ ì¶”ì²œ (ì„ í˜¸ì‚¬í•­ ë°˜ì˜)
4. ì˜ˆì‚° ë°°ë¶„
5. ë‚ ì”¨ ì •ë³´ ë° ì¤€ë¹„ë¬¼
6. êµí†µ ì •ë³´

ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ë¥¼ í™œìš©í•˜ì—¬ ì‹¤ì œ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³ , êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì—¬í–‰ ê³„íšì„ ì œê³µí•˜ì„¸ìš”."""),
        ("user", "{input}"),
        MessagesPlaceholder("agent_scratchpad")
    ])
    
    agent = create_openai_tools_agent(llm, mock_tools, prompt)
    agent_executor = AgentExecutor(agent=agent, tools=mock_tools, verbose=True)
    
    return agent_executor


def display_thinking_process():
    """Display the agent's thinking process with tool executions"""
    if "tool_executions" not in st.session_state or not st.session_state.tool_executions:
        return
    
    st.markdown("### ğŸ¤” Agentê°€ ì‘ì—… ì¤‘ì…ë‹ˆë‹¤...")
    
    # Group tools by status
    running_tools = [t for t in st.session_state.tool_executions if t.get("status") == "running"]
    completed_tools = [t for t in st.session_state.tool_executions if t.get("status") == "completed"]
    error_tools = [t for t in st.session_state.tool_executions if t.get("status") == "error"]
    
    # Show running tools first
    if running_tools:
        st.markdown("#### ğŸ”„ ì‹¤í–‰ ì¤‘ì¸ ë„êµ¬")
        for idx, tool_exec in enumerate(running_tools[-3:]):  # Show last 3 running
            tool_name = tool_exec.get("name", "unknown")
            emoji = get_tool_emoji(tool_name)
            st.info(f"{emoji} **{tool_name}** ì‹¤í–‰ ì¤‘... | ì…ë ¥: {tool_exec.get('input', 'N/A')[:100]}")
    
    # Show completed tools
    if completed_tools:
        st.markdown("#### âœ… ì™„ë£Œëœ ë„êµ¬")
    for idx, tool_exec in enumerate(completed_tools[-5:]):  # Show last 5 completed
        tool_name = tool_exec.get("name", "unknown")
        emoji = get_tool_emoji(tool_name)
        start_time = tool_exec.get("start_time", "")
        unique_key = f"completed_{tool_name}_{idx}_{hash(str(start_time))}"
        
        with st.expander(f"{emoji} âœ… {tool_name} - ì™„ë£Œ", expanded=False, key=f"expander_{unique_key}"):
            st.info(f"**ì…ë ¥:** {tool_exec.get('input', 'N/A')}")
            output = tool_exec.get('output', 'N/A')
            if len(str(output)) > 500:
                st.text_area("**ì¶œë ¥:**", value=str(output)[:500] + "...", height=100, disabled=True, key=f"output_{unique_key}")
            else:
                st.text_area("**ì¶œë ¥:**", value=str(output), height=100, disabled=True, key=f"output_{unique_key}")
    
    # Show error tools
    if error_tools:
        st.markdown("#### âŒ ì˜¤ë¥˜ê°€ ë°œìƒí•œ ë„êµ¬")
    for idx, tool_exec in enumerate(error_tools):
        tool_name = tool_exec.get("name", "unknown")
        emoji = get_tool_emoji(tool_name)
        start_time = tool_exec.get("start_time", "")
        unique_key = f"error_{tool_name}_{idx}_{hash(str(start_time))}"
        
        with st.expander(f"{emoji} âŒ {tool_name} - ì˜¤ë¥˜", expanded=True, key=f"expander_error_{unique_key}"):
            st.error(f"**ì—ëŸ¬:** {tool_exec.get('error', 'Unknown error')}")
            st.info(f"**ì…ë ¥:** {tool_exec.get('input', 'N/A')}")


def initialize_session_state():
    """Initialize Streamlit session state variables"""
    if "messages" not in st.session_state:
        st.session_state.messages = []
    
    if "tool_executions" not in st.session_state:
        st.session_state.tool_executions = []
    
    if "OPENAI_API_KEY" not in st.session_state:
        st.session_state.OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
    
    if "TAVILY_API_KEY" not in st.session_state:
        st.session_state.TAVILY_API_KEY = os.getenv("TAVILY_API_KEY", "")
    
    if "model" not in st.session_state:
        st.session_state.model = "gpt-4o-mini"
    
    if "temperature" not in st.session_state:
        st.session_state.temperature = 0.0
    
    if "use_mock" not in st.session_state:
        st.session_state.use_mock = False
    
    if "pending_query" not in st.session_state:
        st.session_state.pending_query = None


def execute_agent_query(user_query: str):
    """Execute agent with user query and display results"""
    # Clear previous tool executions
    st.session_state.tool_executions = []
    
    # Initialize agent
    try:
        agent_executor, is_mock = initialize_agent(use_mock=st.session_state.use_mock)
        
        # Display assistant message area
        with st.chat_message("assistant"):
            if is_mock:
                st.info("âš ï¸ ê°œë°œ ëª¨ë“œ: Mock Agentë¥¼ ì‚¬ìš© ì¤‘ì…ë‹ˆë‹¤")
            
            # ì‹¤ì‹œê°„ tool ê²°ê³¼ í‘œì‹œìš© ì»¨í…Œì´ë„ˆ
            realtime_results = st.container()
            
            # Initialize callback handler with result container
            callback_handler = StreamlitAgentCallbackHandler(result_container=realtime_results)
            
            # Execute agent
            with st.spinner("ğŸ¤” ì—¬í–‰ ê³„íš ìƒì„± ì¤‘..."):
                try:
                    result = agent_executor.invoke(
                        {"input": user_query},
                        {"callbacks": [callback_handler]}
                    )
                    
                    # Display final response
                    st.markdown("---")
                    st.markdown("### ğŸ“‹ ìµœì¢… ì—¬í–‰ ê³„íš")
                    response = result.get("output", "ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    
                    # D-Day ì •ë³´ê°€ tool_executionsì— ìˆëŠ”ì§€ í™•ì¸í•˜ê³  ì¶”ê°€
                    d_day_info = None
                    for tool_exec in st.session_state.tool_executions:
                        if tool_exec.get("name") == "calculate_d_day" and tool_exec.get("status") == "completed":
                            output = tool_exec.get("output")
                            if isinstance(output, dict):
                                d_day_info = output
                            elif isinstance(output, str):
                                try:
                                    import json
                                    d_day_info = json.loads(output)
                                except:
                                    pass
                            break
                    
                    # D-Day ì •ë³´ê°€ ìˆìœ¼ë©´ ì‘ë‹µ ì•ì— ì¶”ê°€
                    if d_day_info and "formatted" in d_day_info:
                        d_day_section = f"""
### ğŸ“… ì—¬í–‰ D-Day ì •ë³´

- **ì¶œë°œì¼**: {d_day_info.get('date', 'N/A')}
- **D-Day**: {d_day_info.get('formatted', 'N/A')}
- **ë‚¨ì€ ì¼ìˆ˜**: {d_day_info.get('d_day', 'N/A')}ì¼
- **ì¤€ë¹„ ê¸°ê°„**: {d_day_info.get('preparation', {}).get('weeks', 'N/A')}ì£¼
- **ì¤€ë¹„ ê¸´ê¸‰ë„**: {d_day_info.get('preparation', {}).get('urgency', 'N/A')}

---
"""
                        response = d_day_section + response
                    
                    st.markdown(response)
                    
                    # Save to chat history (í•œ ë²ˆë§Œ ì €ì¥)
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": response,
                        "tool_executions": st.session_state.tool_executions.copy()
                    })
                    
                except Exception as e:
                    error_msg = str(e)
                    
                    # Check for specific error types
                    if "api" in error_msg.lower() or "key" in error_msg.lower():
                        st.error("âŒ API í‚¤ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
                    elif "rate limit" in error_msg.lower():
                        st.error("â±ï¸ API í˜¸ì¶œ í•œë„ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
                    else:
                        st.error("ğŸ˜” ì ì‹œ ë¬¸ì œê°€ ìƒê²¼ì–´ìš”. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
                    
                    # Show error details in expander for debugging
                    with st.expander("ğŸ” ì˜¤ë¥˜ ìƒì„¸ ì •ë³´ (ê°œë°œìš©)"):
                        st.exception(e)
                    
                    # Save error message to chat
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": "ì£„ì†¡í•©ë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
                        "error": error_msg
                    })
    
    except Exception as e:
        st.error("ğŸ˜” Agent ì´ˆê¸°í™” ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        with st.expander("ğŸ” ì˜¤ë¥˜ ìƒì„¸ ì •ë³´ (ê°œë°œìš©)"):
            st.exception(e)


def main():
    """Main Streamlit application"""
    initialize_session_state()
    
    # Title
    st.title("âœˆï¸ ì—¬í–‰ ê³„íš Agent")
    st.markdown("---")
    
    # Sidebar
    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì •")
        
        # API Keys
        st.subheader("ğŸ”‘ API í‚¤")
        openai_key = st.text_input(
            "OpenAI API Key",
            value=st.session_state.OPENAI_API_KEY,
            type="password",
            help="OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”"
        )
        if openai_key:
            st.session_state.OPENAI_API_KEY = openai_key
            os.environ["OPENAI_API_KEY"] = openai_key
        
        tavily_key = st.text_input(
            "Tavily API Key",
            value=st.session_state.TAVILY_API_KEY,
            type="password",
            help="Tavily API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì„ íƒì‚¬í•­)"
        )
        if tavily_key:
            st.session_state.TAVILY_API_KEY = tavily_key
            os.environ["TAVILY_API_KEY"] = tavily_key
        
        st.markdown("---")
        
        # Model Settings
        st.subheader("ğŸ¤– ëª¨ë¸ ì„¤ì •")
        model = st.selectbox(
            "ëª¨ë¸ ì„ íƒ",
            ["gpt-4o-mini", "gpt-4o", "gpt-4-turbo"],
            index=0 if st.session_state.model == "gpt-4o-mini" else 1
        )
        st.session_state.model = model
        
        temperature = st.slider("Temperature", 0.0, 1.0, float(st.session_state.temperature), 0.1)
        st.session_state.temperature = temperature
        
        st.markdown("---")
        
        # Development Mode
        st.subheader("ğŸ› ï¸ ê°œë°œ ëª¨ë“œ")
        use_mock = st.checkbox("Mock Agent ì‚¬ìš© (ê°œë°œìš©)", value=st.session_state.use_mock)
        st.session_state.use_mock = use_mock
        
        if use_mock:
            st.warning("âš ï¸ Mock Agent ëª¨ë“œ í™œì„±í™”")
        
        st.markdown("---")
        
        # Clear Chat
        if st.button("ğŸ—‘ï¸ ì±„íŒ… ê¸°ë¡ ì§€ìš°ê¸°"):
            st.session_state.messages = []
            st.session_state.tool_executions = []
            st.rerun()
    
    # Main area
    # Input form for quick start
    with st.expander("ğŸ“ ë¹ ë¥¸ ì‹œì‘ (ì—¬í–‰ ì •ë³´ ì…ë ¥)", expanded=False):
        col1, col2 = st.columns(2)
        with col1:
            destination = st.text_input("ëª©ì ì§€", placeholder="ì˜ˆ: ì œì£¼ë„")
            duration = st.text_input("ê¸°ê°„", placeholder="ì˜ˆ: 3ë°• 4ì¼")
        with col2:
            budget = st.text_input("ì˜ˆì‚°", placeholder="ì˜ˆ: 50ë§Œì›")
            preferences = st.text_input("ì„ í˜¸ì‚¬í•­", placeholder="ì˜ˆ: í•´ì‚°ë¬¼ ì¢‹ì•„í•´")
        
        example_query = st.button("ğŸ“‹ ì˜ˆì œ ì¿¼ë¦¬ ì‚¬ìš©", help="3ë°• 4ì¼ ì œì£¼ë„ ì—¬í–‰ ê³„íš ì§œì¤˜, ì˜ˆì‚° 50ë§Œì›, í•´ì‚°ë¬¼ ì¢‹ì•„í•´")
        
        if st.button("ğŸš€ ì—¬í–‰ ê³„íš ìš”ì²­") or example_query:
            query_parts = []
            if destination or example_query:
                if example_query:
                    user_input = "3ë°• 4ì¼ ì œì£¼ë„ ì—¬í–‰ ê³„íš ì§œì¤˜, ì˜ˆì‚° 50ë§Œì›, í•´ì‚°ë¬¼ ì¢‹ì•„í•´"
                else:
                    query_parts = []
                    if destination:
                        query_parts.append(f"ëª©ì ì§€: {destination}")
                    if duration:
                        query_parts.append(f"ê¸°ê°„: {duration}")
                    if budget:
                        query_parts.append(f"ì˜ˆì‚°: {budget}")
                    if preferences:
                        query_parts.append(f"ì„ í˜¸ì‚¬í•­: {preferences}")
                    user_input = ", ".join(query_parts) if query_parts else destination
                
                # Add to chat
                st.session_state.messages.append({"role": "user", "content": user_input})
                # Store the query to process it after rerun
                st.session_state.pending_query = user_input
                st.rerun()
    
    # Display chat history (ì´ë¯¸ ì™„ë£Œëœ ë©”ì‹œì§€ë§Œ í‘œì‹œ)
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
            
            # Show tool executions if this is an assistant message (ì™„ë£Œëœ ê²ƒë§Œ)
            if message["role"] == "assistant" and "tool_executions" in message:
                # ì™„ë£Œëœ tool executionsë§Œ í‘œì‹œ (ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ëŠ” execute_agent_queryì—ì„œ ì²˜ë¦¬)
                if st.session_state.tool_executions:
                    # ì´ë¯¸ ì™„ë£Œëœ ë©”ì‹œì§€ì´ë¯€ë¡œ ê°„ë‹¨íˆ í‘œì‹œ
                    pass
    
    # Process pending query from button click
    if st.session_state.pending_query:
        pending = st.session_state.pending_query
        st.session_state.pending_query = None  # Clear pending query
        execute_agent_query(pending)
    
    # Chat input
    if prompt := st.chat_input("ì—¬í–‰ ê³„íšì„ ìš”ì²­í•˜ì„¸ìš”..."):
        # Add user message
        st.session_state.messages.append({"role": "user", "content": prompt})
        execute_agent_query(prompt)


if __name__ == "__main__":
    main()
